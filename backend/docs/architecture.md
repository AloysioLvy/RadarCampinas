# ğŸ—ï¸ Arquitetura da Base de Conhecimento - Radar Campinas

## ğŸ“‹ Ãndice

1. [VisÃ£o Geral](#visÃ£o-geral)
2. [DecisÃ£o: Migrations vs Banco Fixo](#decisÃ£o-migrations-vs-banco-fixo)
3. [Arquitetura de Dois Bancos](#arquitetura-de-dois-bancos)
4. [Schemas e Tabelas](#schemas-e-tabelas)
5. [Fluxo de GeraÃ§Ã£o da KB](#fluxo-de-geraÃ§Ã£o-da-kb)
6. [Pipeline de CI/CD](#pipeline-de-cicd)
7. [ExecuÃ§Ã£o Manual](#execuÃ§Ã£o-manual)
8. [Monitoramento e Qualidade](#monitoramento-e-qualidade)

---

## ğŸ¯ VisÃ£o Geral

O sistema **Radar Campinas** Ã© uma plataforma de anÃ¡lise preditiva de criminalidade que utiliza machine learning para prever padrÃµes criminais na cidade de Campinas/SP. A **Base de Conhecimento** (KB - Knowledge Base) Ã© o coraÃ§Ã£o do sistema, agregando dados histÃ³ricos, externos e features engenheiradas para alimentar os modelos de IA.

### Objetivos da KB

- **Consolidar** dados histÃ³ricos de crimes do banco legado
- **Enriquecer** com dados externos (clima, eventos, feriados)
- **Gerar features** temporais e espaciais para ML
- **Validar** qualidade dos dados processados
- **Facilitar** acesso aos dados para treinamento de modelos

---

## ğŸ¤” DecisÃ£o: Migrations vs Banco Fixo

### âœ… **RecomendaÃ§Ã£o: Migrations AutomÃ¡ticas (Escolha Implementada)**

Decidimos implementar **migrations automÃ¡ticas** que sÃ£o executadas sempre que a rota `/api/v1/knowledge-base/generate` Ã© acessada. Esta decisÃ£o foi tomada apÃ³s anÃ¡lise cuidadosa dos prÃ³s e contras de cada abordagem.

### ğŸ“Š ComparaÃ§Ã£o das Abordagens

| Aspecto | ğŸ—ï¸ Migrations AutomÃ¡ticas | ğŸ—„ï¸ Banco Fixo PrÃ©-configurado |
|---------|---------------------------|-------------------------------|
| **Versionamento** | âœ… Versionado em Git | âŒ DifÃ­cil versionar estrutura |
| **Reprodutibilidade** | âœ… ReproduzÃ­vel em qualquer ambiente | âš ï¸ Requer setup manual |
| **CI/CD** | âœ… TestÃ¡vel em pipeline | âš ï¸ Requer DB de staging |
| **Onboarding** | âœ… Novo dev sÃ³ clona repo | âŒ Precisa receber dump/instruÃ§Ãµes |
| **Rollback** | âœ… Git revert + re-run | âŒ Backup/restore manual |
| **EvoluÃ§Ã£o** | âœ… Adicionar campos Ã© simples | âš ï¸ Precisa coordenar mudanÃ§as |
| **Drift** | âœ… Migrations garantem consistÃªncia | âŒ DBs podem divergir |
| **Performance inicial** | âš ï¸ 1-2s na primeira execuÃ§Ã£o | âœ… InstantÃ¢neo |
| **DocumentaÃ§Ã£o** | âœ… Schema Ã© cÃ³digo | âš ï¸ DocumentaÃ§Ã£o externa |

### ğŸ¯ Por que Migrations Venceu?

#### **1. Versionamento e Git**
```sql
-- Migrations sÃ£o cÃ³digo! Posso fazer:
git log internal/database/migrations/
git diff HEAD~1 knowledge_base_schema.sql
git blame knowledge_base_schema.sql
```

#### **2. Reprodutibilidade Total**
```bash
# Novo desenvolvedor:
git clone <repo>
go run cmd/server/main.go  # Migrations aplicadas automaticamente!
```

#### **3. IdempotÃªncia**
```go
// Migrations sÃ£o idempotentes - pode rodar N vezes
CREATE TABLE IF NOT EXISTS curated.incidents ...
CREATE SCHEMA IF NOT EXISTS external ...
```

#### **4. Testabilidade em CI/CD**
```yaml
# GitHub Actions testa migrations em cada commit
test-migrations:
  - Apply migrations on fresh Postgres
  - Verify schemas created
  - Test idempotency
```

#### **5. EvoluÃ§Ã£o Incremental**
```sql
-- v1.0.0: Schema inicial
CREATE TABLE curated.incidents (...)

-- v1.1.0: Adicionar campo (futuro)
ALTER TABLE curated.incidents ADD COLUMN IF NOT EXISTS risk_score FLOAT;
```

### âš ï¸ Desvantagens do Banco Fixo (Por que NÃƒO escolhemos)

#### **1. Schema Drift**
```
Dev 1: Adiciona coluna localmente
Dev 2: Trabalha com schema antigo
ProduÃ§Ã£o: Schema diferente dos dois!
âŒ Disaster waiting to happen
```

#### **2. Onboarding Complexo**
```
Novo dev: Como setup o banco?
Senior: Baixa esse dump de 2GB...
         Ou roda esse script...
         Mas cuidado com os dados sensÃ­veis...
âŒ Friction desnecessÃ¡ria
```

#### **3. Difficult Rollbacks**
```
Bug no schema novo?
Banco fixo: pg_dump, pg_restore, rezar...
Migrations: git revert + re-run
âœ… Clean & predictable
```

### ğŸ’¡ Quando Banco Fixo Faria Sentido?

Banco fixo seria vÃ¡lido apenas se:
- Sistema 100% estÃ¡vel, zero mudanÃ§as no schema
- Dados sensÃ­veis que nÃ£o podem ser recriados
- Performance crÃ­tica (mas migrations levam ~1-2s)
- Equipe muito pequena (1-2 devs)

**Para nosso caso**: Estamos em desenvolvimento ativo, evoluindo o schema, com CI/CD, entÃ£o migrations sÃ£o a escolha Ã³bvia! ğŸ¯

---

## ğŸ—„ï¸ Arquitetura de Dois Bancos

### Diagrama

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ğŸ¢ SOURCE DATABASE (Legado)                   â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   reports   â”‚    â”‚ crimes       â”‚    â”‚ neighborhoods    â”‚   â”‚
â”‚  â”‚             â”‚    â”‚              â”‚    â”‚                  â”‚   â”‚
â”‚  â”‚ - report_id â”‚â”€â”€â”€â–¶â”‚ - crime_id   â”‚    â”‚ - neighborhood_idâ”‚   â”‚
â”‚  â”‚ - crime_id  â”‚    â”‚ - crime_name â”‚    â”‚ - name           â”‚   â”‚
â”‚  â”‚ - neigh_id  â”‚â”€â”€â”€â–¶â”‚ - weight     â”‚â—€â”€â”€â”€â”‚ - lat, lon       â”‚   â”‚
â”‚  â”‚ - date      â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ - weight         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â”‚ ETL Process
                              â”‚ (KnowledgeBaseGenerator)
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ğŸ¯ TARGET DATABASE (KB para IA)                 â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ ğŸ“Š SCHEMA: curated (Dados Processados)                   â”‚   â”‚
â”‚  â”‚  â”œâ”€ incidents    : Crimes transformados + enriquecidos   â”‚   â”‚
â”‚  â”‚  â””â”€ cells        : Grade espacial (500m ou 1000m)        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ ğŸŒ SCHEMA: external (Dados Externos)                     â”‚   â”‚
â”‚  â”‚  â”œâ”€ weather      : Clima (temperatura, chuva, etc)       â”‚   â”‚
â”‚  â”‚  â”œâ”€ holidays     : Feriados nacionais/municipais         â”‚   â”‚
â”‚  â”‚  â””â”€ events       : Shows, jogos, manifestaÃ§Ãµes           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ âš™ï¸ SCHEMA: features (ML Features)                         â”‚   â”‚
â”‚  â”‚  â””â”€ cell_hourly  : Features por cÃ©lula e hora            â”‚   â”‚
â”‚  â”‚                    (lags, rolling windows, temporais)     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ ğŸ“ˆ SCHEMA: analytics (Metadados)                          â”‚   â”‚
â”‚  â”‚  â”œâ”€ quality_reports : MÃ©tricas de qualidade              â”‚   â”‚
â”‚  â”‚  â””â”€ pipeline_logs   : Logs de execuÃ§Ã£o                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Por que Dois Bancos?

#### **Source DB (Legado)**
- **PropÃ³sito**: Dados operacionais do sistema antigo
- **Schema**: NÃ£o controlamos, jÃ¡ existe
- **Tecnologia**: PostgreSQL padrÃ£o
- **ConteÃºdo**: `reports`, `crimes`, `neighborhoods`
- **Acesso**: Apenas leitura (no KB Generator)

#### **Target DB (KB)**
- **PropÃ³sito**: Base otimizada para IA preditiva
- **Schema**: Controlamos 100%, desenhado para ML
- **Tecnologia**: PostgreSQL + PostGIS (geoespacial)
- **ConteÃºdo**: 4 schemas especializados
- **Acesso**: Leitura/escrita (KB Generator + modelos ML)

### BenefÃ­cios da SeparaÃ§Ã£o

1. **Isolamento**: Sistema legado nÃ£o Ã© afetado
2. **Performance**: Ãndices otimizados para queries de ML
3. **Escalabilidade**: Podemos escalar KB independentemente
4. **SeguranÃ§a**: Credenciais separadas
5. **Flexibilidade**: Podemos adicionar outros sources no futuro

---

## ğŸ“Š Schemas e Tabelas

### 1ï¸âƒ£ Schema: `curated`
**PropÃ³sito**: Dados processados e curados de crimes

#### Tabela: `curated.incidents`
```sql
CREATE TABLE curated.incidents (
    id VARCHAR(50) PRIMARY KEY,            -- rpt_123
    occurred_at TIMESTAMP NOT NULL,        -- Quando ocorreu
    category VARCHAR(50) NOT NULL,         -- Hediondo / Comum
    severity INTEGER (1-10),               -- Gravidade
    geom GEOGRAPHY(POINT, 4326),           -- PostGIS point
    neighborhood VARCHAR(100),             -- Bairro
    confidence FLOAT (0-1),                -- Score de confianÃ§a
    source VARCHAR(50),                    -- legacy_reports
    cell_id VARCHAR(50),                   -- CAMP-500-1234
    cell_resolution INTEGER,               -- 500 ou 1000
    created_at TIMESTAMP,
    updated_at TIMESTAMP
);
```

#### Tabela: `curated.cells`
```sql
CREATE TABLE curated.cells (
    cell_id VARCHAR(50) PRIMARY KEY,       -- CAMP-500-1234
    cell_resolution INTEGER NOT NULL,      -- 500 ou 1000 metros
    city VARCHAR(50),                      -- Campinas
    geom GEOGRAPHY(POLYGON, 4326),         -- PolÃ­gono da cÃ©lula
    created_at TIMESTAMP
);
```

**Ãndices Espaciais**: GiST indexes para queries geoespaciais rÃ¡pidas

---

### 2ï¸âƒ£ Schema: `external`
**PropÃ³sito**: Dados externos que influenciam criminalidade

#### Tabela: `external.weather`
```sql
CREATE TABLE external.weather (
    id SERIAL PRIMARY KEY,
    timestamp TIMESTAMP NOT NULL,
    rain_mm FLOAT,                         -- PrecipitaÃ§Ã£o
    temp_c FLOAT,                          -- Temperatura
    humidity FLOAT,                        -- Umidade
    wind_speed FLOAT,                      -- Vento
    pressure FLOAT,                        -- PressÃ£o atmosfÃ©rica
    city VARCHAR(50),
    source VARCHAR(50),
    created_at TIMESTAMP,
    UNIQUE(timestamp, city)
);
```

#### Tabela: `external.holidays`
```sql
CREATE TABLE external.holidays (
    id SERIAL PRIMARY KEY,
    date DATE NOT NULL,
    name VARCHAR(100) NOT NULL,            -- Natal, Tiradentes, etc
    type VARCHAR(50),                      -- nacional, estadual, municipal
    city VARCHAR(50),
    created_at TIMESTAMP,
    UNIQUE(date, city)
);
```

#### Tabela: `external.events`
```sql
CREATE TABLE external.events (
    id SERIAL PRIMARY KEY,
    timestamp TIMESTAMP NOT NULL,
    name VARCHAR(200) NOT NULL,            -- Show no EstÃ¡dio
    geom GEOGRAPHY(POINT, 4326),           -- LocalizaÃ§Ã£o
    attendance INTEGER,                    -- PÃºblico estimado
    type VARCHAR(50),                      -- show, esporte, feira
    impact_radius INTEGER,                 -- 1000 metros
    city VARCHAR(50),
    source VARCHAR(50),
    created_at TIMESTAMP,
    UNIQUE(timestamp, name, city)
);
```

**Por que isso importa?**: Crimes aumentam perto de eventos, em dias chuvosos, em feriados, etc.

---

### 3ï¸âƒ£ Schema: `features`
**PropÃ³sito**: Features engenheiradas para modelos de ML

#### Tabela: `features.cell_hourly`
```sql
CREATE TABLE features.cell_hourly (
    id SERIAL PRIMARY KEY,
    cell_id VARCHAR(50) NOT NULL,
    ts TIMESTAMP NOT NULL,
    
    -- Target variable
    y_count INTEGER DEFAULT 0,             -- Crimes nesta hora
    
    -- Lag features (valores passados)
    lag_1h INTEGER DEFAULT 0,              -- Crimes 1h atrÃ¡s
    lag_24h INTEGER DEFAULT 0,             -- Crimes 24h atrÃ¡s
    lag_7d INTEGER DEFAULT 0,              -- Crimes 7 dias atrÃ¡s
    
    -- Rolling window features
    roll_3h_sum INTEGER DEFAULT 0,         -- Soma Ãºltimas 3h
    roll_24h_sum INTEGER DEFAULT 0,        -- Soma Ãºltimas 24h
    roll_7d_sum INTEGER DEFAULT 0,         -- Soma Ãºltimos 7 dias
    roll_7d_avg FLOAT,                     -- MÃ©dia Ãºltimos 7 dias
    roll_7d_std FLOAT,                     -- Desvio padrÃ£o
    
    -- Temporal features
    dow INTEGER,                           -- Dia da semana (0-6)
    hour INTEGER,                          -- Hora do dia (0-23)
    is_weekend BOOLEAN,                    -- Ã‰ fim de semana?
    is_business_hours BOOLEAN,             -- HorÃ¡rio comercial?
    
    -- Weather features
    weather_rain_mm FLOAT,
    weather_temp_c FLOAT,
    weather_humidity FLOAT,
    
    -- Calendar features
    holiday BOOLEAN DEFAULT FALSE,
    day_before_holiday BOOLEAN DEFAULT FALSE,
    day_after_holiday BOOLEAN DEFAULT FALSE,
    
    -- Event features
    nearby_events INTEGER DEFAULT 0,
    event_attendance INTEGER DEFAULT 0,
    
    -- Spatial features
    neighbor_avg_crime FLOAT,              -- MÃ©dia dos vizinhos
    
    created_at TIMESTAMP,
    updated_at TIMESTAMP,
    UNIQUE(cell_id, ts)
);
```

**Por que tantas features?**: Modelos de ML precisam de contexto temporal e espacial para fazer boas prediÃ§Ãµes.

---

### 4ï¸âƒ£ Schema: `analytics`
**PropÃ³sito**: Metadados e monitoramento

#### Tabela: `analytics.quality_reports`
```sql
CREATE TABLE analytics.quality_reports (
    id SERIAL PRIMARY KEY,
    report_date DATE UNIQUE NOT NULL,
    metrics JSONB NOT NULL,                -- {spatial_coverage: 0.85, ...}
    created_at TIMESTAMP,
    updated_at TIMESTAMP
);
```

#### Tabela: `analytics.pipeline_logs`
```sql
CREATE TABLE analytics.pipeline_logs (
    id SERIAL PRIMARY KEY,
    execution_id UUID UNIQUE NOT NULL,
    started_at TIMESTAMP NOT NULL,
    finished_at TIMESTAMP,
    status VARCHAR(20),                    -- running, success, failed
    phase VARCHAR(50),                     -- migrate, spatial_grid, etc
    records_processed INTEGER,
    error_message TEXT,
    execution_time_seconds INTEGER,
    created_at TIMESTAMP
);
```

---

## ğŸ”„ Fluxo de GeraÃ§Ã£o da KB

### SequÃªncia de ExecuÃ§Ã£o

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ POST /api/v1/knowledge-base/generate                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ”§ FASE 0: Run Migrations                                       â”‚
â”‚ â”œâ”€ Verificar se migrations jÃ¡ aplicadas (idempotente)           â”‚
â”‚ â”œâ”€ Executar knowledge_base_schema.sql                           â”‚
â”‚ â”œâ”€ Criar schemas: curated, external, features, analytics        â”‚
â”‚ â”œâ”€ Criar tabelas + Ã­ndices + views + functions                  â”‚
â”‚ â””â”€ Log: analytics.pipeline_logs                                 â”‚
â”‚ â±ï¸  Tempo: ~1-2 segundos (primeira vez), ~0.1s (subsequentes)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“Š FASE 1: Migrate Historical Data                              â”‚
â”‚ â”œâ”€ Query: SELECT reports JOIN neighborhoods JOIN crimes         â”‚
â”‚ â”œâ”€ Transform: report â†’ incident (mapear categorias)             â”‚
â”‚ â”œâ”€ Validate: coordenadas dentro de Campinas                     â”‚
â”‚ â”œâ”€ Batch insert: curated.incidents (500-1000 registros/lote)    â”‚
â”‚ â””â”€ Log: registros processados + ignorados                       â”‚
â”‚ â±ï¸  Tempo: ~10-30 segundos (10k registros)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ—ºï¸  FASE 2: Generate Spatial Grid                               â”‚
â”‚ â”œâ”€ Calcular cÃ©lulas para bounding box de Campinas               â”‚
â”‚ â”œâ”€ ResoluÃ§Ã£o: 500m ou 1000m (configurÃ¡vel)                      â”‚
â”‚ â”œâ”€ Gerar polÃ­gonos: ST_MakeEnvelope(lon, lat, lon+Î´, lat+Î´)    â”‚
â”‚ â”œâ”€ Batch insert: curated.cells (~200-800 cÃ©lulas)               â”‚
â”‚ â””â”€ Log: cÃ©lulas geradas                                         â”‚
â”‚ â±ï¸  Tempo: ~2-5 segundos                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ¯ FASE 3: Assign Cells to Incidents                            â”‚
â”‚ â”œâ”€ Spatial join: ST_Contains(cell.geom, incident.geom)          â”‚
â”‚ â”œâ”€ Update: incidents SET cell_id = cells.cell_id                â”‚
â”‚ â””â”€ Log: incidentes atribuÃ­dos                                   â”‚
â”‚ â±ï¸  Tempo: ~5-10 segundos (10k registros)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸŒ¦ï¸  FASE 4: Ingest External Data                                â”‚
â”‚ â”œâ”€ Weather: Inserir dados de clima (API ou mock)                â”‚
â”‚ â”œâ”€ Holidays: Inserir calendÃ¡rio de feriados 2025                â”‚
â”‚ â”œâ”€ Events: Inserir eventos relevantes (shows, jogos)            â”‚
â”‚ â””â”€ Log: total de registros externos                             â”‚
â”‚ â±ï¸  Tempo: ~1-3 segundos (dados mock)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âš™ï¸  FASE 5: Generate Temporal Features                          â”‚
â”‚ â”œâ”€ Para cada hora no perÃ­odo (StartDate â†’ EndDate):             â”‚
â”‚ â”‚   â”œâ”€ Calcular y_count (crimes nesta hora)                     â”‚
â”‚ â”‚   â”œâ”€ Calcular lags (1h, 24h, 7d atrÃ¡s)                        â”‚
â”‚ â”‚   â”œâ”€ Calcular rolling windows (3h, 24h, 7d)                   â”‚
â”‚ â”‚   â”œâ”€ Adicionar features temporais (dow, hour, weekend)        â”‚
â”‚ â”‚   â”œâ”€ Join com weather                                         â”‚
â”‚ â”‚   â”œâ”€ Join com holidays                                        â”‚
â”‚ â”‚   â””â”€ INSERT/UPDATE features.cell_hourly                       â”‚
â”‚ â””â”€ Log: horas processadas                                       â”‚
â”‚ â±ï¸  Tempo: ~30-120 segundos (1 ano de dados)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âœ“ FASE 6: Validate Data Quality                                â”‚
â”‚ â”œâ”€ Calcular mÃ©tricas:                                           â”‚
â”‚ â”‚   â”œâ”€ Cobertura espacial: cÃ©lulas com dados / total cÃ©lulas    â”‚
â”‚ â”‚   â”œâ”€ Cobertura temporal: horas com dados / total horas        â”‚
â”‚ â”‚   â”œâ”€ Taxa de duplicaÃ§Ã£o: duplicados / total                   â”‚
â”‚ â”‚   â””â”€ Completude de features: % campos preenchidos             â”‚
â”‚ â”œâ”€ Inserir analytics.quality_reports                            â”‚
â”‚ â”œâ”€ ValidaÃ§Ãµes crÃ­ticas:                                         â”‚
â”‚ â”‚   â”œâ”€ Cobertura espacial > 10%? âœ“                              â”‚
â”‚ â”‚   â””â”€ Taxa duplicaÃ§Ã£o < 50%? âœ“                                 â”‚
â”‚ â””â”€ Log: mÃ©tricas de qualidade                                   â”‚
â”‚ â±ï¸  Tempo: ~3-5 segundos                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âœ… SUCESSO! Base de conhecimento gerada                         â”‚
â”‚ â±ï¸  Tempo total: ~1-3 minutos (1 ano de dados)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Pipeline de CI/CD

### VisualizaÃ§Ã£o no GitHub Actions

O pipeline Ã© organizado em **6 stages sequenciais** com dependÃªncias claras:

```
STAGE 1: VALIDATE          STAGE 2: BUILD          STAGE 3: TEST
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Lint Go      â”‚â”€â”€â”€â”        â”‚              â”‚        â”‚ Unit Tests   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚        â”‚              â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”œâ”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Build App    â”‚â”€â”€â”€â”€â”€â”€â”€â–¶â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Validate SQL â”‚â”€â”€â”€â”¤        â”‚              â”‚        â”‚ Integration  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚        â”‚              â”‚        â”‚ Tests        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ Security Scanâ”‚â”€â”€â”€â”˜                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
                                                            â–¼
STAGE 4: MIGRATE           STAGE 5: DEPLOY         STAGE 6: NOTIFY
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              â”‚            â”‚              â”‚        â”‚ Notify       â”‚
â”‚ Test         â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Generate KB  â”‚â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Success      â”‚
â”‚ Migrations   â”‚            â”‚ (schedule)   â”‚        â”‚              â”‚
â”‚              â”‚            â”‚              â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Stages Detalhados

#### Stage 1: Validate (Parallel)
- **lint-go**: golangci-lint para code quality
- **validate-sql**: Verificar sintaxe SQL
- **security-scan**: Gosec para vulnerabilidades

#### Stage 2: Build
- **build-app**: Compilar binÃ¡rio Go
- Upload artifact para stages seguintes

#### Stage 3: Test (Parallel)
- **unit-tests**: Tests unitÃ¡rios + coverage
- **integration-tests**: Tests com PostgreSQL real

#### Stage 4: Migrate
- **test-migrations**: Aplicar em DB temporÃ¡rio
- Verificar schemas e tabelas criados
- Testar idempotÃªncia

#### Stage 5: Deploy (Conditional)
- **generate-knowledge-base**: Executar geraÃ§Ã£o completa
- Apenas em schedule ou manual trigger
- Usa Docker containers para DBs

#### Stage 6: Notify
- **notify-success**: NotificaÃ§Ã£o em caso de sucesso
- **notify-failure**: NotificaÃ§Ã£o em caso de falha

### Gatilhos de ExecuÃ§Ã£o

```yaml
# 1. Schedule (1x por semana)
schedule:
  - cron: '0 3 * * 1'  # Segunda Ã s 3h

# 2. Manual (via GitHub UI)
workflow_dispatch:
  inputs:
    days_back: 365
    cell_resolution: 500

# 3. Push (apenas testes, nÃ£o gera KB)
push:
  branches: [main, develop]
  paths: ['internal/**', '.github/workflows/**']
```

---

## ğŸ–¥ï¸ ExecuÃ§Ã£o Manual

### OpÃ§Ã£o 1: Via API (Recomendado)

```bash
# Fazer request para a rota
curl -X POST http://localhost:8080/api/v1/knowledge-base/generate

# Response esperado
{
  "status": "Base de conhecimento gerada com sucesso"
}
```

### OpÃ§Ã£o 2: Via Script Shell

```bash
# Executar script auxiliar
./scripts/run_kb_generation.sh

# Com parÃ¢metros personalizados
./scripts/run_kb_generation.sh --days-back=180 --cell-resolution=1000
```

### OpÃ§Ã£o 3: Via Go Direto

```bash
# Compilar e executar
go build -o radar-kb ./cmd/server
./radar-kb generate-kb
```

### OpÃ§Ã£o 4: Docker Compose

```bash
# Subir DBs + aplicaÃ§Ã£o
docker-compose up -d

# Executar geraÃ§Ã£o
docker-compose exec app /app/radar-kb generate-kb
```

---

## ğŸ“Š Monitoramento e Qualidade

### MÃ©tricas Coletadas

```json
{
  "spatial_coverage": 0.85,      // 85% das cÃ©lulas tÃªm dados
  "temporal_coverage": 0.92,     // 92% das horas tÃªm dados
  "duplication_rate": 0.03,      // 3% de duplicaÃ§Ã£o
  "feature_completeness": 0.98   // 98% das features preenchidas
}
```

### Queries Ãšteis

```sql
-- Ver Ãºltimas execuÃ§Ãµes do pipeline
SELECT 
    execution_id,
    started_at,
    finished_at,
    status,
    phase,
    records_processed
FROM analytics.pipeline_logs
ORDER BY started_at DESC
LIMIT 10;

-- Ver cÃ©lulas com mais crimes
SELECT 
    cell_id,
    COUNT(*) as crime_count,
    AVG(severity) as avg_severity
FROM curated.incidents
WHERE occurred_at >= NOW() - INTERVAL '30 days'
GROUP BY cell_id
ORDER BY crime_count DESC
LIMIT 10;

-- Ver features de uma cÃ©lula especÃ­fica
SELECT *
FROM features.cell_hourly
WHERE cell_id = 'CAMP-500-1234'
ORDER BY ts DESC
LIMIT 24;  -- Ãºltimas 24 horas
```

### Alertas

O sistema valida automaticamente:
- âœ… Cobertura espacial > 10%
- âœ… Taxa de duplicaÃ§Ã£o < 50%
- âš ï¸ Se falhar, erro Ã© retornado

---

## ğŸ” Troubleshooting

### Erro: "relation curated.cells does not exist"

**Causa**: Migrations nÃ£o foram executadas

**SoluÃ§Ã£o**:
```bash
# 1. Verificar se arquivo existe
ls -la internal/database/migrations/knowledge_base_schema.sql

# 2. Aplicar manualmente
psql -h localhost -U postgres -d radar_campinas -f internal/database/migrations/knowledge_base_schema.sql

# 3. Verificar schemas
psql -h localhost -U postgres -d radar_campinas -c "\dn"
```

### Performance Lenta

**OtimizaÃ§Ãµes**:
- Aumentar `BatchSize` no config (padrÃ£o: 500)
- Reduzir perÃ­odo de `StartDate` / `EndDate`
- Usar `cell_resolution` maior (1000m ao invÃ©s de 500m)
- Criar Ã­ndices adicionais se necessÃ¡rio

### Dados Faltando

**VerificaÃ§Ãµes**:
```sql
-- Quantos incidentes foram migrados?
SELECT COUNT(*) FROM curated.incidents;

-- Quantas cÃ©lulas foram geradas?
SELECT COUNT(*) FROM curated.cells;

-- Quantas features foram geradas?
SELECT COUNT(*) FROM features.cell_hourly;
```

---

## ğŸ“š ReferÃªncias

- [PostGIS Documentation](https://postgis.net/docs/)
- [PostgreSQL Migration Best Practices](https://www.postgresql.org/docs/current/ddl-schemas.html)
- [GitHub Actions CI/CD Guide](https://docs.github.com/en/actions)
- [Go Database/SQL Tutorial](https://go.dev/doc/database/querying)

---

## ğŸ¤ Contribuindo

Para adicionar uma nova feature ou schema:

1. Editar `internal/database/migrations/knowledge_base_schema.sql`
2. Incrementar versÃ£o (ex: v1.0.0 â†’ v1.1.0)
3. Testar localmente
4. Abrir PR com descriÃ§Ã£o das mudanÃ§as
5. Pipeline CI/CD valida automaticamente

---

**Ãšltima atualizaÃ§Ã£o**: 2025-10-09  
**VersÃ£o**: 1.0.0  
**Autor**: TCC Radar Campinas 
